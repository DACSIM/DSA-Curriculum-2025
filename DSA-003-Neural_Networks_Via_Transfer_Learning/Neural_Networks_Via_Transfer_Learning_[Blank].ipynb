{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EuWUsRa0l3o"
      },
      "outputs": [],
      "source": [
        "# === Cell 1 (Corrected): Install dependencies without version pinning ===\n",
        "!pip install \\\n",
        "    gradio \\\n",
        "    pandas \\\n",
        "    matplotlib \\\n",
        "    seaborn \\\n",
        "    scikit-learn \\\n",
        "    numpy \\\n",
        "    pillow \\\n",
        "    opencv-python \\\n",
        "    tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCZ_sFVW0ygv"
      },
      "outputs": [],
      "source": [
        "# === Cell 2 (Corrected): All imports ===\n",
        "\n",
        "# 1) Standard library\n",
        "import os, glob\n",
        "import io, base64\n",
        "\n",
        "# 2) Data & visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 3) TensorFlow & Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Input\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.optimizers import Adam, AdamW  # <-- FINAL CORRECTION HERE\n",
        "from tensorflow.keras.optimizers.schedules import CosineDecayRestarts\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Dense\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import CategoricalFocalCrossentropy\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "# 4) TensorFlow Add-Ons is no longer needed\n",
        "\n",
        "# 5) Scikit-learn utilities\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# 6) OpenCV & PIL (for any image I/O)\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from IPython.display import display, HTML\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import output, files\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Cy0KmOms29Mi"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# === Cell 8: Left-Aligned Webcam & Upload UI with Continuous Emotion Prediction ===\n",
        "\n",
        "# --- Constants ---\n",
        "VIDEO_WIDTH, VIDEO_HEIGHT = 640, 480\n",
        "IMAGE_SIZE = 128 # model input height/width\n",
        "\n",
        "# --- Load model & build single-trace inference fn ---\n",
        "model = load_model(\"FER_MobileNetV2_best.h5\")\n",
        "@tf.function\n",
        "def predict_fn(x):\n",
        "    # run the model in inference mode, returns (batch, 7) tensor\n",
        "    return model(x, training=False)\n",
        "\n",
        "# --- Emotion labels & face detector ---\n",
        "emotion_labels = {\n",
        "    0: \"Angry\", 1: \"Disgust\", 2: \"Fear\",\n",
        "    3: \"Happy\", 4: \"Sad\",     5: \"Surprise\",\n",
        "    6: \"Neutral\"\n",
        "}\n",
        "face_cascade = cv2.CascadeClassifier(\n",
        "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
        ")\n",
        "\n",
        "# --- Helper: detect faces, preprocess, predict, annotate ---\n",
        "def annotate_frame(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
        "    for (x, y, w, h) in faces:\n",
        "        face = frame[y:y+h, x:x+w]\n",
        "        face_rgb = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
        "        resized = cv2.resize(face_rgb, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "        inp = preprocess_input(resized.astype(\"float32\"))\n",
        "        inp = tf.expand_dims(inp, axis=0)  # shape (1, IMAGE_SIZE, IMAGE_SIZE, 3)\n",
        "        preds = predict_fn(inp).numpy()[0]\n",
        "        idx = int(np.argmax(preds))\n",
        "        label = emotion_labels.get(idx, \"Unknown\")\n",
        "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, label, (x, y - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "    return frame\n",
        "\n",
        "# --- JavaScript UI: left-aligned video + bottom buttons ---\n",
        "def start_webcam_ui():\n",
        "    js = rf\"\"\"\n",
        "    <script>\n",
        "      const cid = 'emotion-container';\n",
        "      document.getElementById(cid)?.remove();\n",
        "      const c = document.createElement('div');\n",
        "      c.id = cid;\n",
        "      c.style.display = 'flex';\n",
        "      c.style.flexDirection = 'column';\n",
        "      c.style.alignItems = 'flex-start';\n",
        "      c.style.margin = '10px';\n",
        "      document.body.appendChild(c);\n",
        "\n",
        "      const v = document.createElement('video');\n",
        "      v.width = {VIDEO_WIDTH}; v.height = {VIDEO_HEIGHT}; v.autoplay = true;\n",
        "      c.appendChild(v);\n",
        "\n",
        "      navigator.mediaDevices.getUserMedia({{video:true}})\n",
        "        .then(s => {{\n",
        "          v.srcObject = s;\n",
        "          setTimeout(() => {{\n",
        "            const bar = document.createElement('div');\n",
        "            bar.style.marginTop = '10px';\n",
        "            c.appendChild(bar);\n",
        "\n",
        "            const snap = document.createElement('button');\n",
        "            snap.textContent = 'Capture Photo';\n",
        "            bar.appendChild(snap);\n",
        "\n",
        "            const upl = document.createElement('button');\n",
        "            upl.textContent = 'Upload Image';\n",
        "            bar.appendChild(upl);\n",
        "\n",
        "            snap.onclick = () => {{\n",
        "              const canvas = document.createElement('canvas');\n",
        "              canvas.width = {VIDEO_WIDTH};\n",
        "              canvas.height = {VIDEO_HEIGHT};\n",
        "              canvas.getContext('2d').drawImage(v, 0, 0);\n",
        "              const dataUrl = canvas.toDataURL('image/png');\n",
        "              google.colab.kernel.invokeFunction('notebook.on_capture', [dataUrl], {{}});\n",
        "            }};\n",
        "            upl.onclick = () => {{\n",
        "              google.colab.kernel.invokeFunction('notebook.on_upload', [], {{}});\n",
        "            }};\n",
        "          }}, 1000);\n",
        "        }})\n",
        "        .catch(e => alert('Webcam not accessible: ' + e));\n",
        "    </script>\n",
        "    \"\"\"\n",
        "    display(HTML(js))\n",
        "\n",
        "# --- Callback: process a captured screenshot ---\n",
        "def on_capture(dataUrl):\n",
        "    header, encoded = dataUrl.split(\",\", 1)\n",
        "    img = Image.open(io.BytesIO(base64.b64decode(encoded))).convert(\"RGB\")\n",
        "    frame = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "    # frame is already VIDEO_WIDTHÃ—VIDEO_HEIGHT\n",
        "    annotated = annotate_frame(frame)\n",
        "    cv2_imshow(annotated)\n",
        "\n",
        "# --- Callback: process an uploaded image ---\n",
        "def on_upload():\n",
        "    uploaded = files.upload()\n",
        "    for fname in uploaded:\n",
        "        img = Image.open(fname).convert(\"RGB\")\n",
        "        frame = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n",
        "        frame = cv2.resize(frame, (VIDEO_WIDTH, VIDEO_HEIGHT))\n",
        "        annotated = annotate_frame(frame)\n",
        "        cv2_imshow(annotated)\n",
        "\n",
        "# --- Register callbacks & launch UI ---\n",
        "output.register_callback('notebook.on_capture', on_capture)\n",
        "output.register_callback('notebook.on_upload', on_upload)\n",
        "start_webcam_ui()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}